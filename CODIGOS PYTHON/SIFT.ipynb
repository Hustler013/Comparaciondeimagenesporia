{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdJVFcWvQZo-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from skimage.feature import match_descriptors, plot_matches, SIFT\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "import time\n",
        "\n",
        "# Código que quieres medir\n",
        "start_time = time.time()\n",
        "\n",
        "# Ruta donde se encuentran las imágenes (cambia por tu ruta)\n",
        "carpeta_imagenes_español = 'BING/ESP/*.jpg'\n",
        "carpeta_imagenes_ingles = 'BING/ENG/*.jpg'\n",
        "\n",
        "# Lista para almacenar las imágenes\n",
        "img1 = []\n",
        "img2 = []\n",
        "\n",
        "# Obtener la lista de nombres de archivo de las imágenes en la carpeta\n",
        "archivos_imagenes1 = glob.glob(carpeta_imagenes_español)\n",
        "archivos_imagenes2 = glob.glob(carpeta_imagenes_ingles)\n",
        "\n",
        "# Recorrer la lista de nombres de archivo y leer las imágenes\n",
        "for nombre_archivo in archivos_imagenes1:\n",
        "    # Imprimir el nombre de la imagen\n",
        "    #print(f\"Leyendo: {nombre_archivo}\")\n",
        "    # Leer la imagen y añadirla a la lista\n",
        "    imagen = cv2.imread(nombre_archivo, cv2.IMREAD_GRAYSCALE)\n",
        "    #imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "    if imagen is not None:\n",
        "        img1.append(imagen)\n",
        "\n",
        "for nombre_archivo in archivos_imagenes2:\n",
        "    # Imprimir el nombre de la imagen\n",
        "    #print(f\"Leyendo: {nombre_archivo}\")\n",
        "    # Leer la imagen y añadirla a la lista\n",
        "    imagen = cv2.imread(nombre_archivo, cv2.IMREAD_GRAYSCALE)\n",
        "    #imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "    if imagen is not None:\n",
        "        img2.append(imagen)\n",
        "\n",
        "tform = transform.AffineTransform(scale=(1.3, 1.1), rotation=0.5, translation=(0, -200))\n",
        "\n",
        "# Definición de extractor SIFT\n",
        "descriptor_extractor = SIFT()\n",
        "\n",
        "# Variables para keypoints y descriptores\n",
        "keypoints1 = []\n",
        "keypoints2 = []\n",
        "descriptors1 = []\n",
        "descriptors2 = []\n",
        "\n",
        "# Procesar las imágenes para obtener keypoints y descriptores de las imágenes en español\n",
        "for img in img1:\n",
        "    descriptor_extractor.detect_and_extract(img)\n",
        "    keypoints1.append(descriptor_extractor.keypoints)\n",
        "    descriptors1.append(descriptor_extractor.descriptors)\n",
        "\n",
        "# Procesar las imágenes para obtener    keypoints y descriptores de las imágenes en inglés\n",
        "for img in img2:\n",
        "    descriptor_extractor.detect_and_extract(img)\n",
        "    keypoints2.append(descriptor_extractor.keypoints)\n",
        "    descriptors2.append(descriptor_extractor.descriptors)\n",
        "\n",
        "#Comparación Descriptores Imagen 1 con Imagen 2\n",
        "for i in range(len(img1)):\n",
        "    matches = match_descriptors(descriptors1[i], descriptors2[i], max_ratio=0.6, cross_check=True)\n",
        "    #print(descriptors1[i])\n",
        "    n=510 #510 numero de descriptores\n",
        "    d=np.zeros((n,1))\n",
        "    for j, match in enumerate(matches):\n",
        "        idx1, idx2 = match  # Índices del descriptor en la primera y segunda imagen\n",
        "        if idx1 < len(descriptors1[i]) and idx2 < len(descriptors2[i]):\n",
        "            d[j] = np.linalg.norm(descriptors1[i][idx1] - descriptors2[i][idx2])\n",
        "        else:\n",
        "            print(\"Index out of bounds or descriptors not found\")\n",
        "\n",
        "    D = np.mean(d)\n",
        "    #print(D)\n",
        "    print(f\"Distancia del emparejamiento {i+1}: {D}\")\n",
        "\n",
        "# Comparación Descriptores Imagen 1 con Imagen 2\n",
        "for i in range(len(img1)):\n",
        "    matches12 = match_descriptors(descriptors1[i], descriptors2[i], max_ratio=0.6, cross_check=True)\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(11, 8))\n",
        "    plt.gray()\n",
        "\n",
        "    plot_matches(ax[0], img1[i], img2[i], keypoints1[i], keypoints2[i], matches12)\n",
        "    ax[0].axis('off')\n",
        "    ax[0].set_title(\"Imagen Español vs. Imagen Ingles\\n\"\n",
        "                   \"(todos los keypoints y coincidencias)\")\n",
        "\n",
        "    plot_matches(ax[1], img1[i], img2[i], keypoints1[i], keypoints2[i], matches12[::15], only_matches=True)\n",
        "    ax[1].axis('off')\n",
        "    ax[1].set_title(\"Imagen Español vs. Imagen Ingles\\n\"\n",
        "                   \"(subconjunto de coincidencias para visibilidad)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "end_time = time.time()\n",
        "# Tiempo transcurrido en segundos\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Convertir a minutos y segundos\n",
        "minutes = int(elapsed_time // 60)\n",
        "seconds = int(elapsed_time % 60)\n",
        "\n",
        "print(f\"El tiempo transcurrido es: {minutes} minutos y {seconds} segundos\")"
      ]
    }
  ]
}